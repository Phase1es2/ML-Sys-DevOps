# compress_export.py

import os
import torch
import torch.nn as nn
from model_def import DepthProForSuperResolution, get_depthpro_model

# ==== 1. åŠ è½½å‹ç¼©ç‰ˆ DepthPro æ¨¡å‹ ====
print("ğŸ“¦ Loading compressed DepthPro model...")
depth_model = get_depthpro_model(compressed=True)

# ==== 2. æ„å»ºè¶…åˆ†æ¨¡å‹ ====
model = DepthProForSuperResolution(depth_model)
model.eval()

# ä¸Šä¼ åŸå§‹çš„
# # æ„å»ºç»“æ„ï¼ˆä¿æŒå‹ç¼©ç‰ˆé…ç½®ä¸€è‡´ï¼‰
# depth_model = get_depthpro_model(compressed=True)
# model = DepthProForSuperResolution(depth_model)

# # âœ… åŠ è½½ä½ è®­ç»ƒå¥½çš„å‚æ•°
# model.load_state_dict(torch.load("depthpro_sr_trained.pth", map_location="cpu"))

# model.eval()


# ==== 3. ä¿å­˜åŸå§‹ï¼ˆæœªé‡åŒ–ï¼‰æ¨¡å‹ ====
torch.save(model.state_dict(), "depthpro_sr_compressed.pth")
print("âœ… Saved: depthpro_sr_compressed.pth")

# ==== 4. åŠ¨æ€é‡åŒ– ====
print("ğŸ”§ Applying dynamic quantization...")
# åªé‡åŒ– image_head å’Œ headï¼Œè€Œä¸æ˜¯æ•´ä¸ª DepthPro æ¨¡å‹
model.image_head = torch.quantization.quantize_dynamic(
    model.image_head, {nn.Linear}, dtype=torch.qint8
)
model.head = torch.quantization.quantize_dynamic(
    model.head, {nn.Linear}, dtype=torch.qint8
)

# æ³¨æ„ï¼šä¸è§¦ç¢° model.depthpro_for_depth_estimationï¼Œä¿æŒåŸæ ·
quantized_model = model  # å®‰å…¨åœ°ç»§ç»­ç”¨å®ƒ
torch.save(quantized_model.state_dict(), "depthpro_sr_quantized.pth")
print("âœ… Saved: depthpro_sr_quantized.pth")

# ==== 5. å¯¼å‡ºä¸º ONNX ====
print("ğŸ“¤ Exporting to ONNX...")
dummy_input = torch.randn(1, 3, 64, 64)
onnx_path = "depthpro_sr_compressed.onnx"
torch.onnx.export(
    quantized_model,
    dummy_input,
    onnx_path,
    input_names=["input"],
    output_names=["output"],
    dynamic_axes={"input": {0: "batch_size"}, "output": {0: "batch_size"}},
    export_params=True,
    opset_version=17,
    do_constant_folding=True
)
print(f"âœ… Saved: {onnx_path}")

# ==== 6. TorchScript å¯¼å‡º ====
print("ğŸ“¤ Exporting to TorchScript...")
traced = torch.jit.trace(quantized_model, dummy_input)
traced.save("depthpro_sr_quantized.pt")
print("âœ… Saved: depthpro_sr_quantized.pt")

# ==== 7. æ˜¾ç¤ºæ¨¡å‹å¤§å° ====
def show_size(path):
    mb = os.path.getsize(path) / (1024 * 1024)
    print(f"ğŸ“¦ {path}: {mb:.2f} MB")

for path in [
    "depthpro_sr_compressed.pth",
    "depthpro_sr_quantized.pth",
    "depthpro_sr_quantized.pt",
    "depthpro_sr_compressed.onnx"
]:
    show_size(path)